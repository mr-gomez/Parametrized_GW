{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reload modified python modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing parameter spaces\n",
    "In this notebook, we test the gradient descent code that finds:\n",
    "1. An optimal coupling between distinct parameter spaces\n",
    "2. An optimal weight on a shared parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Optimal transport\n",
    "from ot.gromov import gromov_wasserstein\n",
    "from utils.gw_ms import gromov_wasserstein_ms, compute_dGWs\n",
    "from utils.gw_ms import gw_ms_couple_nu, gw_ms_learn_nu\n",
    "from utils.utils import stepwise_pdist\n",
    "\n",
    "# Graph functions\n",
    "import networkx as nx\n",
    "\n",
    "# Utilities\n",
    "from time import time\n",
    "\n",
    "from utils.classification_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coupling parameter spaces\n",
    "I will generate one pm-net, then reverse the order. Hopefully the parameter coupling recognizes the reordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.full_rary_tree(3, 10)\n",
    "print(G.number_of_nodes())\n",
    "\n",
    "nx.draw(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single multiscale network\n",
    "N = 20\n",
    "G1 = nx.cycle_graph(N)\n",
    "G2 = nx.full_rary_tree(3, N)\n",
    "\n",
    "# Obtain distance matrices\n",
    "dm1 = nx.floyd_warshall_numpy(G1)\n",
    "dm2 = nx.floyd_warshall_numpy(G2)\n",
    "\n",
    "# Create multiscale sequences with different orders\n",
    "lC1 = [dm1, dm2]\n",
    "lC2 = [dm2, dm1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(9, 3))\n",
    "ims = [None] * 2\n",
    "\n",
    "for i in range(2):\n",
    "    im = axes[i].imshow(lC1[i], vmin=0, aspect=\"auto\")\n",
    "    plt.colorbar(im, ax=axes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nu1 = unif(2)\n",
    "nu1 = np.array([0.7, 0.3])\n",
    "nu2 = np.flip(nu1)\n",
    "# nu2 = nu1\n",
    "E, T, log, logE, logG = gw_ms_couple_nu(\n",
    "    lC1, lC2, nu1=nu1, nu2=nu2, log=True, verbose=True\n",
    ")\n",
    "print()\n",
    "\n",
    "print(f\"The distance between the sequnces is: {log['loss'][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(9, 3))\n",
    "ims = [None] * 2\n",
    "ims[0] = axes[0].imshow(E, vmin=0, aspect=\"auto\")\n",
    "ims[1] = axes[1].imshow(T, vmin=0, aspect=\"auto\")\n",
    "\n",
    "for i in range(2):\n",
    "    plt.colorbar(ims[i], ax=axes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric learning -- dynamic metric spaces\n",
    "In this setting, I have a shared parameter space with unknown weights, for example, dynamic metric spaces where the parameter space is time. We want to learn the weights on the parameter space that minimize the classification error of the parametrized GW distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and arena parameters\n",
    "shape = (5, 5)\n",
    "nSteps = 5\n",
    "dx = 0.6\n",
    "room_length = nSteps * dx\n",
    "\n",
    "# Number of instances in each class\n",
    "n_copies = 5\n",
    "\n",
    "# Noise\n",
    "rng = np.random.default_rng(304)\n",
    "std = 0.05\n",
    "\n",
    "# Obstacle parameters\n",
    "obstacles = [\n",
    "    {\"center\": None, \"radii\": None},\n",
    "    {\"center\": (1.5, 0), \"radii\": (0.5, 0.7)},\n",
    "    # {'center': (1.0, 0), 'radii': (0.5,0.7)},\n",
    "    # {'center': (3.0, 0), 'radii': (0.5,0.7)},\n",
    "]\n",
    "n_classes = len(obstacles)\n",
    "\n",
    "# Create obstacle function for each set of parameters\n",
    "# and store\n",
    "for i in range(len(obstacles)):\n",
    "    # Create obstacle function\n",
    "    params = obstacles[i]\n",
    "    obstacle = create_obstacle_fun(**params)\n",
    "\n",
    "    # Store\n",
    "    params[\"obstacle\"] = obstacle\n",
    "    obstacles[i] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base sequences\n",
    "seqs_0 = []\n",
    "for params in obstacles:\n",
    "    seq = moving_point_grid(shape, dx, nSteps, params[\"obstacle\"])\n",
    "    seqs_0.append(seq)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Part 1: Generate graphs and their invariants\n",
    "# ---------------------------------------------\n",
    "seqs_all = []\n",
    "lCs_all = []  # Store lCs as a big list\n",
    "\n",
    "for idc in range(n_classes):\n",
    "    seqs_class = []\n",
    "    lCs_class = []\n",
    "\n",
    "    params = obstacles[idc]\n",
    "    center = params[\"center\"]\n",
    "    radii = params[\"radii\"]\n",
    "    obstacle = params[\"obstacle\"]\n",
    "\n",
    "    # Sample several instances\n",
    "    for j in range(n_copies):\n",
    "        P_seq = seqs_0[idc].copy()\n",
    "\n",
    "        # Add noise and compute distances\n",
    "        for t in range(nSteps):\n",
    "            P_seq[t, :, :] = add_noise_avoid_obstacle(\n",
    "                P_seq[t, :, :], std, center, obstacle, rng=rng\n",
    "            )\n",
    "\n",
    "            H = stepwise_pdist(P_seq)\n",
    "\n",
    "        # Accumulate one instance\n",
    "        seqs_class.append(P_seq)\n",
    "        lCs_class.append(H)\n",
    "\n",
    "    # Accumulate all instances of the class\n",
    "    seqs_all.append(np.array(seqs_class))\n",
    "    lCs_all.extend(lCs_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class labels, and obtain cost functions\n",
    "N = len(lCs_all)\n",
    "\n",
    "y_true = np.repeat(np.arange(n_classes), n_copies).astype(int)\n",
    "Is = np.reshape(np.arange(N), (n_classes, -1)).astype(int)\n",
    "\n",
    "S, dS = S_multi_class_fixed(Is, N)\n",
    "\n",
    "print(\"Num. sequences:\", N)\n",
    "print(\"True labels:\")\n",
    "print(y_true)\n",
    "print()\n",
    "\n",
    "print(\"Classes:\")\n",
    "print(Is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first element of each class\n",
    "for idc in range(n_classes):\n",
    "    seq = seqs_all[idc][0, :, :]\n",
    "\n",
    "    params = obstacles[idc]\n",
    "    center = params[\"center\"]\n",
    "    radii = params[\"radii\"]\n",
    "\n",
    "    if center is None or radii is None:\n",
    "        plot_obstacle = False\n",
    "    else:\n",
    "        plot_obstacle = True\n",
    "\n",
    "    fig, ax = plot_drone_grid(\n",
    "        seq, room_length, center, radii, plot_obstacle=plot_obstacle, seq_id=idc + 1\n",
    "    )\n",
    "    # plt.savefig(f'../output/paper/Drone_seq_{idc+1}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponents = np.arange(-3, 2).astype(int)\n",
    "max_iter = 25\n",
    "\n",
    "for exp in exponents:\n",
    "    print(\" -------------------------- \")\n",
    "    print(f\"Regularization: 10**({exp})\")\n",
    "    print()\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # Part 2: Compute distances\n",
    "    # ---------------------------------------------\n",
    "    dGWs = compute_dGWs(nSteps, lCs_all, verbose=0)\n",
    "\n",
    "    # Compute dMS and learn weights\n",
    "    lambda_S = 10.0 ** (exp)\n",
    "    time_start = time()\n",
    "    dMSs, Ts, nu, score, info = gw_ms_learn_nu(\n",
    "        lCs_all,\n",
    "        S=S,\n",
    "        dS=dS,\n",
    "        lambda_S=lambda_S,\n",
    "        loss_fun=\"square_loss\",\n",
    "        option=1,\n",
    "        log=False,\n",
    "        verbose=0,\n",
    "        max_iter=max_iter,\n",
    "        tol_rel=1e-15,\n",
    "        tol_abs=1e-15,\n",
    "    )\n",
    "    score_list, abs_delta_list, rel_delta_list, nu_list = info\n",
    "    time_end = time()\n",
    "    dt = time_end - time_start\n",
    "\n",
    "    dMSs = np.maximum(dMSs, 0)\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # Part 3: Output\n",
    "    # ---------------------------------------------\n",
    "    fig1, axes1, fig2, axes2 = plot_score_and_deltas(\n",
    "        score_list, abs_delta_list, rel_delta_list, nu_list\n",
    "    )\n",
    "\n",
    "    invariant_names = np.arange(nSteps).tolist()\n",
    "    fig3, axes3, im3 = MS_output(dGWs, dMSs, nu, S, invariant_names)\n",
    "\n",
    "    # print(\"Metric learning:\")\n",
    "    # print(nu)\n",
    "    # print(\"Score: {:3f}\".format(S(dMSs, p=1)))\n",
    "\n",
    "    # fig4, ax4 = show_couplings(Ts)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and arena parameters\n",
    "shape = (5, 5)\n",
    "nSteps = 5\n",
    "dx = 0.6\n",
    "room_length = nSteps * dx\n",
    "\n",
    "# Number of instances in each class\n",
    "n_neighbors = 3\n",
    "\n",
    "# Noise\n",
    "rng = np.random.default_rng(304)\n",
    "std = 0.05\n",
    "\n",
    "# Optimization parameters\n",
    "lambda_S = 1e-1\n",
    "max_iter = 10\n",
    "\n",
    "# Obstacle parameters\n",
    "obstacles = [\n",
    "    {\"center\": None, \"radii\": None},\n",
    "    {\"center\": (1.5, 0), \"radii\": (0.5, 0.7)},\n",
    "    # {'center': (1.0, 0), 'radii': (0.5,0.7)},\n",
    "    # {'center': (3.0, 0), 'radii': (0.5,0.7)},\n",
    "]\n",
    "n_classes = len(obstacles)\n",
    "\n",
    "# Create obstacle function for each set of parameters\n",
    "# and store\n",
    "for i in range(len(obstacles)):\n",
    "    # Create obstacle function\n",
    "    params = obstacles[i]\n",
    "    obstacle = create_obstacle_fun(**params)\n",
    "\n",
    "    # Store\n",
    "    params[\"obstacle\"] = obstacle\n",
    "    obstacles[i] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nReps = 20\n",
    "\n",
    "copies_train = 30\n",
    "copies_test = 30\n",
    "n_copies = copies_train + copies_test\n",
    "\n",
    "I_train = np.arange(copies_train).astype(int)\n",
    "I_test = np.arange(copies_train, n_copies).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base sequences\n",
    "seqs_0 = []\n",
    "for params in obstacles:\n",
    "    seq = moving_point_grid(shape, dx, nSteps, params[\"obstacle\"])\n",
    "    seqs_0.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idc in range(n_classes):\n",
    "    seq = seqs_0[idc]\n",
    "\n",
    "    params = obstacles[idc]\n",
    "    center = params[\"center\"]\n",
    "    radii = params[\"radii\"]\n",
    "\n",
    "    if center is None or radii is None:\n",
    "        plot_obstacle = False\n",
    "    else:\n",
    "        plot_obstacle = True\n",
    "\n",
    "    fig, ax = plot_drone_grid(\n",
    "        seq, room_length, center, radii, plot_obstacle=plot_obstacle, seq_id=idc + 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = np.zeros((nReps, nSteps))\n",
    "accuracies_2 = np.zeros(nReps)\n",
    "accuracies_ms = np.zeros(nReps)\n",
    "accuracies_hard = np.zeros(nReps)\n",
    "accuracies_soft = np.zeros(nReps)\n",
    "\n",
    "for i in range(nReps):\n",
    "    rep_start = time()\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # Part 1: Generate graphs and their invariants\n",
    "    # ---------------------------------------------\n",
    "    seqs_all = []\n",
    "    lCs_all = []\n",
    "\n",
    "    for idc in range(n_classes):\n",
    "        seqs_class = []\n",
    "        lCs_class = []\n",
    "\n",
    "        params = obstacles[idc]\n",
    "        center = params[\"center\"]\n",
    "        radii = params[\"radii\"]\n",
    "        obstacle = params[\"obstacle\"]\n",
    "\n",
    "        # Sample several instances\n",
    "        for j in range(n_copies):\n",
    "            P_seq = seqs_0[idc].copy()\n",
    "\n",
    "            # Add noise and compute distances\n",
    "            for t in range(nSteps):\n",
    "                P_seq[t, :, :] = add_noise_avoid_obstacle(\n",
    "                    P_seq[t, :, :], std, center, obstacle, rng=rng\n",
    "                )\n",
    "\n",
    "                H = stepwise_pdist(P_seq)\n",
    "\n",
    "            # Accumulate one instance\n",
    "            seqs_class.append(P_seq)\n",
    "            lCs_class.append(H)\n",
    "\n",
    "        # Accumulate all instances of the class\n",
    "        seqs_all.append(np.array(seqs_class))\n",
    "        lCs_all.append(np.array(lCs_class))\n",
    "\n",
    "    # Separating training and test sets\n",
    "    # --------------------\n",
    "    N = np.sum([lC.shape[0] for lC in lCs_all])\n",
    "\n",
    "    # Train set\n",
    "    seqs_train = np.concatenate(\n",
    "        [seq_class[I_train, :, :] for seq_class in seqs_all], axis=0\n",
    "    )\n",
    "    lCs_train = np.concatenate(\n",
    "        [lCs_class[I_train, :, :] for lCs_class in lCs_all], axis=0\n",
    "    )\n",
    "\n",
    "    n_train = seqs_train.shape[0]\n",
    "    y_train = np.repeat(np.arange(n_classes), copies_train).astype(int)\n",
    "    Is_train = np.reshape(np.arange(n_train), (n_classes, -1)).astype(int)\n",
    "    S_train, dS_train = S_multi_class_fixed(Is_train, n_train)\n",
    "\n",
    "    # Test set\n",
    "    seqs_test = np.concatenate(\n",
    "        [seq_class[I_test, :, :] for seq_class in seqs_all], axis=0\n",
    "    )\n",
    "    lCs_test = np.concatenate(\n",
    "        [lCs_class[I_test, :, :] for lCs_class in lCs_all], axis=0\n",
    "    )\n",
    "\n",
    "    n_test = seqs_test.shape[0]\n",
    "    y_test = np.repeat(np.arange(n_classes), copies_test).astype(int)\n",
    "    Is_test = np.reshape(np.arange(n_test), (n_classes, -1)).astype(int)\n",
    "    S_test, dS_test = S_multi_class_fixed(Is_test, n_test)\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # Part 2: GW distance benchmark\n",
    "    # ---------------------------------------------\n",
    "    dGWs_train = compute_dGWs(nSteps, lCs_train, verbose=0)\n",
    "\n",
    "    # Compute GW and MS distances between the test set and all the train set\n",
    "    # Since we already have nu, we use a fixed parameter set and fixed measure\n",
    "    dGWs_test = np.zeros((nSteps, n_test, n_train))\n",
    "    for i_test in range(n_test):\n",
    "        lC_test = lCs_test[i_test]\n",
    "        for i_train in range(n_train):\n",
    "            lC_train = lCs_train[i_train]\n",
    "\n",
    "            # GW between individual invariants\n",
    "            for t in range(nSteps):\n",
    "                time_start = time()\n",
    "                _, log = gromov_wasserstein(\n",
    "                    lC_test[t, :, :], lC_train[t, :, :], log=True\n",
    "                )\n",
    "                time_end = time()\n",
    "\n",
    "                dGWs_test[t, i_test, i_train] = log[\"gw_dist\"]\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # Part 3: Compute MS distance and learn nu\n",
    "    # ---------------------------------------------\n",
    "    # Compute dMS and learn weights\n",
    "    time_start = time()\n",
    "    dMSs_train, Ts_train, nu_trained, score, info = gw_ms_learn_nu(\n",
    "        lCs_train,\n",
    "        S=S_train,\n",
    "        dS=dS_train,\n",
    "        lambda_S=lambda_S,\n",
    "        loss_fun=\"square_loss\",\n",
    "        option=1,\n",
    "        log=False,\n",
    "        verbose=0,\n",
    "        max_iter=max_iter,\n",
    "        tol_rel=1e-12,\n",
    "        tol_abs=1e-12,\n",
    "    )\n",
    "    score_list, abs_delta_list, rel_delta_list, nu_list = info\n",
    "    time_end = time()\n",
    "    dt = time_end - time_start\n",
    "\n",
    "    dMSs_train = np.maximum(dMSs_train, 0)\n",
    "\n",
    "    print(\"nu_trained\")\n",
    "    print(nu_trained)\n",
    "    print()\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # Part 4: Compute distances on test set\n",
    "    # ---------------------------------------------\n",
    "    # Compute GW and MS distances between the test set and all the train set\n",
    "    # Since we already have nu, we use a fixed parameter set and fixed measure\n",
    "    dMSs_test = np.zeros((n_test, n_train))\n",
    "\n",
    "    for i_test in range(n_test):\n",
    "        lC_test = lCs_test[i_test]\n",
    "        for i_train in range(n_train):\n",
    "            lC_train = lCs_train[i_train]\n",
    "\n",
    "            # MS with pre-trained weights\n",
    "            time_start = time()\n",
    "            _, log = gromov_wasserstein_ms(\n",
    "                lC_test, lC_train, nu=nu_trained, log=True, verbose=0\n",
    "            )\n",
    "            time_end = time()\n",
    "\n",
    "            dMSs_test[i_test, i_train] = log[\"gw_dist\"]\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # Part 5: Classification experiment\n",
    "    # ---------------------------------------------\n",
    "    (\n",
    "        pred_probs,\n",
    "        accuracy,\n",
    "        accuracy_ms,\n",
    "        accuracy_hard,\n",
    "        accuracy_soft,\n",
    "    ) = classification_experiment(\n",
    "        n_neighbors,\n",
    "        n_classes,\n",
    "        (dGWs_train, dMSs_train, y_train),\n",
    "        (dGWs_test, dMSs_test, y_test),\n",
    "    )\n",
    "    # ---------------------------------------------\n",
    "    # Part 6: Ensemble of the best classifiers\n",
    "    # ---------------------------------------------\n",
    "    # Select only the best classifiers\n",
    "    pred_probs = pred_probs[[2, 4], :, :]\n",
    "    accuracy_2 = np.zeros(2)\n",
    "\n",
    "    # Create ensemble\n",
    "    max_probs = np.max(pred_probs, axis=2)\n",
    "    winners = pred_probs == max_probs[:, :, None]\n",
    "\n",
    "    votes = np.sum(winners, axis=0)\n",
    "    y_pred_hard = votes.argmax(axis=1)\n",
    "\n",
    "    # Rescale accuracies\n",
    "    accuracies[i, :] = 100 * accuracy\n",
    "    accuracies_2[i] = 100 * accuracy_score(y_test, y_pred_hard)\n",
    "    accuracies_ms[i] = 100 * accuracy_ms\n",
    "    accuracies_hard[i] = 100 * accuracy_hard\n",
    "    accuracies_soft[i] = 100 * accuracy_soft\n",
    "\n",
    "    rep_end = time()\n",
    "    print()\n",
    "    print(f\"({i+1}/{nReps}) Time:\", np.round(rep_end - rep_start, 3))\n",
    "    print(\" --------------------- \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(accuracies)\n",
    "# print(accuracies.shape)\n",
    "\n",
    "print(np.array([accuracies.mean(axis=0), accuracies.std(axis=0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracies_ms, linestyle=\"dashed\", color=\"blue\", marker=\".\")\n",
    "plt.plot(accuracies_hard, linestyle=\"solid\", color=\"orange\", marker=\".\")\n",
    "plt.plot(accuracies_soft, linestyle=\"dotted\", color=\"green\", marker=\".\")\n",
    "\n",
    "plt.plot(accuracies_2, linestyle=\"dotted\", color=\"red\")\n",
    "\n",
    "plt.ylim(0, 110)\n",
    "\n",
    "plt.legend([\"MS\", \"Ensemble -- hard\", \"Ensemble -- soft\", \"2-Ensemble\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Multiscale\")\n",
    "print(np.round(accuracies_ms.mean(), 0))\n",
    "print(np.round(accuracies_ms.std(), 0))\n",
    "print()\n",
    "\n",
    "print(\"Accuracy GW Ensemble -- Hard\")\n",
    "print(np.round(accuracies_hard.mean(), 0))\n",
    "print(np.round(accuracies_hard.std(), 0))\n",
    "print()\n",
    "\n",
    "print(\"Accuracy GW Ensemble -- Soft\")\n",
    "print(np.round(accuracies_soft.mean(), 0))\n",
    "print(np.round(accuracies_soft.std(), 0))\n",
    "print()\n",
    "\n",
    "print(\"Accuracy individual GWs\")\n",
    "print(np.round(accuracies_2.mean(), 0))\n",
    "print(np.round(accuracies_2.std(), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
